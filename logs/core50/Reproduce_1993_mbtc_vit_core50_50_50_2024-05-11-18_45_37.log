2024-05-11 18:45:37,608 [trainer.py] => prefix: Reproduce
2024-05-11 18:45:37,608 [trainer.py] => dataset: core50
2024-05-11 18:45:37,608 [trainer.py] => total_sessions: 8
2024-05-11 18:45:37,608 [trainer.py] => memory_size: 0
2024-05-11 18:45:37,608 [trainer.py] => memory_per_class: 0
2024-05-11 18:45:37,608 [trainer.py] => fixed_memory: True
2024-05-11 18:45:37,608 [trainer.py] => fixed_fc: True
2024-05-11 18:45:37,608 [trainer.py] => shuffle: False
2024-05-11 18:45:37,608 [trainer.py] => init_cls: 50
2024-05-11 18:45:37,608 [trainer.py] => increment: 50
2024-05-11 18:45:37,608 [trainer.py] => model_name: duct
2024-05-11 18:45:37,608 [trainer.py] => net_type: vit
2024-05-11 18:45:37,608 [trainer.py] => merge_scalar: 0.25
2024-05-11 18:45:37,609 [trainer.py] => head_merge_ratio: 0.25
2024-05-11 18:45:37,609 [trainer.py] => ot_reg: 0.2
2024-05-11 18:45:37,609 [trainer.py] => lr_re: 0.001
2024-05-11 18:45:37,609 [trainer.py] => epc_re: 5
2024-05-11 18:45:37,609 [trainer.py] => embd_dim: 768
2024-05-11 18:45:37,609 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=2)]
2024-05-11 18:45:37,609 [trainer.py] => seed: 1993
2024-05-11 18:45:37,609 [trainer.py] => EPSILON: 1e-08
2024-05-11 18:45:37,609 [trainer.py] => bcb_lr_scale: 0.001
2024-05-11 18:45:37,609 [trainer.py] => epochs: 10
2024-05-11 18:45:37,609 [trainer.py] => lrate: 0.1
2024-05-11 18:45:37,609 [trainer.py] => milestones: [60, 100, 140]
2024-05-11 18:45:37,609 [trainer.py] => lrate_decay: 0.1
2024-05-11 18:45:37,609 [trainer.py] => weight_decay: 0.0005
2024-05-11 18:45:37,609 [trainer.py] => batch_size: 128
2024-05-11 18:45:37,609 [trainer.py] => num_workers: 16
2024-05-11 18:45:37,609 [trainer.py] => logfilename: logs/Reproduce_1993_mbtc_vit_core50_50_50_2024-05-11-18:45:37
2024-05-11 18:45:37,609 [data.py] => Training sequence of domains: ['s11', 's4', 's2', 's9', 's1', 's6', 's5', 's8']
2024-05-11 18:47:36,241 [data_manager.py] => class order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]
2024-05-11 18:48:06,977 [vit_inc.py] => You are now using `vit_base_patch16_224` as backbone.
2024-05-11 18:48:08,274 [_builder.py] => Loading pretrained weights from url (https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz)
2024-05-11 18:48:10,473 [trainer.py] => All params: 91326184
2024-05-11 18:48:10,474 [trainer.py] => Trainable params: 91326184
2024-05-11 18:48:10,474 [mbtc.py] => Learning on 0-50
2024-05-11 18:49:27,527 [mbtc.py] => Initial epochs: 10
2024-05-11 18:50:44,892 [mbtc.py] => Task 0, Epoch 1/10 => Loss 3.042
2024-05-11 18:50:44,892 [mbtc.py] => {'Train loss': 3.042020546177686}
2024-05-11 18:51:56,514 [mbtc.py] => Task 0, Epoch 2/10 => Loss 0.731
2024-05-11 18:51:56,515 [mbtc.py] => {'Train loss': 0.7311119328616029}
2024-05-11 18:53:07,964 [mbtc.py] => Task 0, Epoch 3/10 => Loss 0.415
2024-05-11 18:53:07,965 [mbtc.py] => {'Train loss': 0.4152506723747415}
2024-05-11 18:54:19,577 [mbtc.py] => Task 0, Epoch 4/10 => Loss 0.326
2024-05-11 18:54:19,577 [mbtc.py] => {'Train loss': 0.32566484493219244}
2024-05-11 18:56:03,761 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 18:57:37,555 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 18:57:37,556 [mbtc.py] => {'Train acc': 95.23, 'Test acc': 89.47}
2024-05-11 18:57:37,556 [mbtc.py] => Task 0, Epoch 5/10 => Loss 0.281, Train_accy 95.230, Test_accy 89.470
2024-05-11 18:57:37,556 [mbtc.py] => {'Train loss': 0.28148645339375833}
2024-05-11 18:58:49,067 [mbtc.py] => Task 0, Epoch 6/10 => Loss 0.268
2024-05-11 18:58:49,068 [mbtc.py] => {'Train loss': 0.26786474144812356}
2024-05-11 19:00:00,799 [mbtc.py] => Task 0, Epoch 7/10 => Loss 0.217
2024-05-11 19:00:00,799 [mbtc.py] => {'Train loss': 0.21651197610012554}
2024-05-11 19:01:12,418 [mbtc.py] => Task 0, Epoch 8/10 => Loss 0.187
2024-05-11 19:01:12,418 [mbtc.py] => {'Train loss': 0.18650759125159957}
2024-05-11 19:02:23,916 [mbtc.py] => Task 0, Epoch 9/10 => Loss 0.171
2024-05-11 19:02:23,917 [mbtc.py] => {'Train loss': 0.17099018565426438}
2024-05-11 19:04:07,945 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:05:40,980 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:05:40,980 [mbtc.py] => {'Train acc': 96.59, 'Test acc': 90.15}
2024-05-11 19:05:40,980 [mbtc.py] => Task 0, Epoch 10/10 => Loss 0.160, Train_accy 96.590, Test_accy 90.150
2024-05-11 19:05:40,981 [mbtc.py] => {'Train loss': 0.1595381009471366}
2024-05-11 19:05:40,997 [mbtc.py] => Merge scalar: 0.25
2024-05-11 19:07:41,592 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:07:41,593 [mbtc.py] => Test accuracy of model after backbone merge: 77.17
2024-05-11 19:08:52,472 [mbtc.py] => Task 0, Epoch 1/5 => Loss 0.399
2024-05-11 19:08:52,472 [mbtc.py] => {'Train loss': 0.3989915211321944}
2024-05-11 19:10:03,229 [mbtc.py] => Task 0, Epoch 2/5 => Loss 0.315
2024-05-11 19:10:03,230 [mbtc.py] => {'Train loss': 0.3152647672568337}
2024-05-11 19:11:14,302 [mbtc.py] => Task 0, Epoch 3/5 => Loss 0.296
2024-05-11 19:11:14,303 [mbtc.py] => {'Train loss': 0.29578059457116207}
2024-05-11 19:12:25,370 [mbtc.py] => Task 0, Epoch 4/5 => Loss 0.295
2024-05-11 19:12:25,370 [mbtc.py] => {'Train loss': 0.2954602170798738}
2024-05-11 19:14:09,155 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:15:42,316 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:15:42,317 [mbtc.py] => {'Train acc': 94.81, 'Test acc': 82.96}
2024-05-11 19:15:42,317 [mbtc.py] => Task 0, Epoch 5/5 => Loss 0.276, Train_accy 94.810, Test_accy 82.960
2024-05-11 19:15:42,317 [mbtc.py] => {'Train loss': 0.2756995364897332}
2024-05-11 19:17:14,939 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:17:14,940 [mbtc.py] => Test accuracy of model after retraining: 82.96
2024-05-11 19:21:18,562 [trainer.py] => MBTC_VIT: {'total': 82.96, '00-49': 82.96, 'old': 0, 'new': 82.96}
2024-05-11 19:21:18,562 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 0, 'new': 2.0}
2024-05-11 19:21:18,562 [trainer.py] => MBTC_VIT top1 curve: [82.96]
2024-05-11 19:21:18,562 [trainer.py] => NME top1 curve: [2.0]
2024-05-11 19:21:18,563 [trainer.py] => Average NME top1: 2.0
2024-05-11 19:21:18,563 [trainer.py] => Average top1: 82.96
2024-05-11 19:21:18,563 [trainer.py] => All params: 91364585
2024-05-11 19:21:18,564 [trainer.py] => Trainable params: 91364585
2024-05-11 19:21:18,564 [mbtc.py] => Learning on 50-100
2024-05-11 19:23:53,160 [mbtc.py] => Task 1, Epoch 1/10 => Loss 3.014
2024-05-11 19:23:53,160 [mbtc.py] => {'Train loss': 3.01406073267177}
2024-05-11 19:25:04,876 [mbtc.py] => Task 1, Epoch 2/10 => Loss 0.673
2024-05-11 19:25:04,876 [mbtc.py] => {'Train loss': 0.6729105615009696}
2024-05-11 19:26:16,511 [mbtc.py] => Task 1, Epoch 3/10 => Loss 0.385
2024-05-11 19:26:16,511 [mbtc.py] => {'Train loss': 0.384916034037784}
2024-05-11 19:27:28,261 [mbtc.py] => Task 1, Epoch 4/10 => Loss 0.315
2024-05-11 19:27:28,262 [mbtc.py] => {'Train loss': 0.31531751282134296}
2024-05-11 19:29:13,039 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:30:46,043 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:30:46,043 [mbtc.py] => {'Train acc': 94.76, 'Test acc': 90.59}
2024-05-11 19:30:46,043 [mbtc.py] => Task 1, Epoch 5/10 => Loss 0.281, Train_accy 94.760, Test_accy 90.590
2024-05-11 19:30:46,044 [mbtc.py] => {'Train loss': 0.2814826400224435}
2024-05-11 19:31:57,882 [mbtc.py] => Task 1, Epoch 6/10 => Loss 0.250
2024-05-11 19:31:57,882 [mbtc.py] => {'Train loss': 0.25038008619162994}
2024-05-11 19:33:09,858 [mbtc.py] => Task 1, Epoch 7/10 => Loss 0.220
2024-05-11 19:33:09,858 [mbtc.py] => {'Train loss': 0.21980263879996234}
2024-05-11 19:34:21,501 [mbtc.py] => Task 1, Epoch 8/10 => Loss 0.196
2024-05-11 19:34:21,502 [mbtc.py] => {'Train loss': 0.1959350496783095}
2024-05-11 19:35:33,264 [mbtc.py] => Task 1, Epoch 9/10 => Loss 0.175
2024-05-11 19:35:33,264 [mbtc.py] => {'Train loss': 0.17494560670802148}
2024-05-11 19:37:18,097 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:38:51,264 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:38:51,265 [mbtc.py] => {'Train acc': 95.89, 'Test acc': 92.41}
2024-05-11 19:38:51,265 [mbtc.py] => Task 1, Epoch 10/10 => Loss 0.173, Train_accy 95.890, Test_accy 92.410
2024-05-11 19:38:51,265 [mbtc.py] => {'Train loss': 0.17266856455954455}
2024-05-11 19:38:51,281 [mbtc.py] => Merge scalar: 0.25
2024-05-11 19:40:52,277 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:40:52,278 [mbtc.py] => Test accuracy of model after backbone merge: 88.99
2024-05-11 19:42:03,169 [mbtc.py] => Task 1, Epoch 1/5 => Loss 0.308
2024-05-11 19:42:03,169 [mbtc.py] => {'Train loss': 0.30840695908261556}
2024-05-11 19:43:13,992 [mbtc.py] => Task 1, Epoch 2/5 => Loss 0.273
2024-05-11 19:43:13,992 [mbtc.py] => {'Train loss': 0.273022524507369}
2024-05-11 19:44:25,081 [mbtc.py] => Task 1, Epoch 3/5 => Loss 0.270
2024-05-11 19:44:25,082 [mbtc.py] => {'Train loss': 0.27035383962221066}
2024-05-11 19:45:35,934 [mbtc.py] => Task 1, Epoch 4/5 => Loss 0.247
2024-05-11 19:45:35,935 [mbtc.py] => {'Train loss': 0.24676937256324089}
2024-05-11 19:47:20,256 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:48:53,489 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:48:53,489 [mbtc.py] => {'Train acc': 94.48, 'Test acc': 89.55}
2024-05-11 19:48:53,489 [mbtc.py] => Task 1, Epoch 5/5 => Loss 0.239, Train_accy 94.480, Test_accy 89.550
2024-05-11 19:48:53,490 [mbtc.py] => {'Train loss': 0.23908837032267602}
2024-05-11 19:50:26,542 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:50:26,542 [mbtc.py] => Test accuracy of model after retraining: 89.55
2024-05-11 19:50:26,852 [mbtc.py] => The OT cost: 43.03958
2024-05-11 19:50:26,852 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 19:50:26,852 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 19:52:28,041 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 19:52:28,042 [mbtc.py] => Test accuracy of model after classifier transport: 89.57
2024-05-11 19:56:33,423 [trainer.py] => MBTC_VIT: {'total': 89.57, '00-49': 89.57, 'old': 89.57, 'new': nan}
2024-05-11 19:56:33,423 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 19:56:33,424 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57]
2024-05-11 19:56:33,424 [trainer.py] => NME top1 curve: [2.0, 2.0]
2024-05-11 19:56:33,424 [trainer.py] => Average NME top1: 2.0
2024-05-11 19:56:33,424 [trainer.py] => Average top1: 86.26499999999999
2024-05-11 19:56:33,425 [trainer.py] => All params: 91402985
2024-05-11 19:56:33,425 [trainer.py] => Trainable params: 91402985
2024-05-11 19:56:33,425 [mbtc.py] => Learning on 100-150
2024-05-11 19:59:08,573 [mbtc.py] => Task 2, Epoch 1/10 => Loss 3.131
2024-05-11 19:59:08,573 [mbtc.py] => {'Train loss': 3.130829164537333}
2024-05-11 20:00:20,269 [mbtc.py] => Task 2, Epoch 2/10 => Loss 0.804
2024-05-11 20:00:20,269 [mbtc.py] => {'Train loss': 0.8040853652913692}
2024-05-11 20:01:32,093 [mbtc.py] => Task 2, Epoch 3/10 => Loss 0.487
2024-05-11 20:01:32,093 [mbtc.py] => {'Train loss': 0.48716978419382695}
2024-05-11 20:02:43,829 [mbtc.py] => Task 2, Epoch 4/10 => Loss 0.413
2024-05-11 20:02:43,830 [mbtc.py] => {'Train loss': 0.41330519406977345}
2024-05-11 20:04:28,416 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:06:01,922 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:06:01,923 [mbtc.py] => {'Train acc': 92.09, 'Test acc': 90.79}
2024-05-11 20:06:01,923 [mbtc.py] => Task 2, Epoch 5/10 => Loss 0.372, Train_accy 92.090, Test_accy 90.790
2024-05-11 20:06:01,923 [mbtc.py] => {'Train loss': 0.372029269271988}
2024-05-11 20:07:13,379 [mbtc.py] => Task 2, Epoch 6/10 => Loss 0.342
2024-05-11 20:07:13,379 [mbtc.py] => {'Train loss': 0.34171762759402646}
2024-05-11 20:08:25,029 [mbtc.py] => Task 2, Epoch 7/10 => Loss 0.304
2024-05-11 20:08:25,029 [mbtc.py] => {'Train loss': 0.3036336531325922}
2024-05-11 20:09:36,709 [mbtc.py] => Task 2, Epoch 8/10 => Loss 0.277
2024-05-11 20:09:36,709 [mbtc.py] => {'Train loss': 0.2774903253983643}
2024-05-11 20:10:48,529 [mbtc.py] => Task 2, Epoch 9/10 => Loss 0.256
2024-05-11 20:10:48,530 [mbtc.py] => {'Train loss': 0.25636765998551403}
2024-05-11 20:12:33,135 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:14:07,482 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:14:07,483 [mbtc.py] => {'Train acc': 94.34, 'Test acc': 92.71}
2024-05-11 20:14:07,483 [mbtc.py] => Task 2, Epoch 10/10 => Loss 0.251, Train_accy 94.340, Test_accy 92.710
2024-05-11 20:14:07,483 [mbtc.py] => {'Train loss': 0.2510899122236139}
2024-05-11 20:14:07,499 [mbtc.py] => Merge scalar: 0.25
2024-05-11 20:16:09,675 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:16:09,677 [mbtc.py] => Test accuracy of model after backbone merge: 92.32
2024-05-11 20:17:21,195 [mbtc.py] => Task 2, Epoch 1/5 => Loss 0.321
2024-05-11 20:17:21,200 [mbtc.py] => {'Train loss': 0.32120397522792976}
2024-05-11 20:18:32,325 [mbtc.py] => Task 2, Epoch 2/5 => Loss 0.309
2024-05-11 20:18:32,326 [mbtc.py] => {'Train loss': 0.30896647021932117}
2024-05-11 20:19:43,485 [mbtc.py] => Task 2, Epoch 3/5 => Loss 0.295
2024-05-11 20:19:43,486 [mbtc.py] => {'Train loss': 0.2946850430157225}
2024-05-11 20:20:54,474 [mbtc.py] => Task 2, Epoch 4/5 => Loss 0.297
2024-05-11 20:20:54,475 [mbtc.py] => {'Train loss': 0.29656232767185925}
2024-05-11 20:22:40,464 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:24:16,750 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:24:16,751 [mbtc.py] => {'Train acc': 92.75, 'Test acc': 92.16}
2024-05-11 20:24:16,751 [mbtc.py] => Task 2, Epoch 5/5 => Loss 0.294, Train_accy 92.750, Test_accy 92.160
2024-05-11 20:24:16,751 [mbtc.py] => {'Train loss': 0.2938587200843682}
2024-05-11 20:25:53,260 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:25:53,261 [mbtc.py] => Test accuracy of model after retraining: 92.16
2024-05-11 20:25:53,544 [mbtc.py] => The OT cost: 61.62560
2024-05-11 20:25:53,544 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 20:25:53,544 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 20:25:53,817 [mbtc.py] => The OT cost: 64.25553
2024-05-11 20:25:53,817 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 20:25:53,817 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 20:27:57,006 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:27:57,006 [mbtc.py] => Test accuracy of model after classifier transport: 92.21
2024-05-11 20:32:08,029 [trainer.py] => MBTC_VIT: {'total': 92.21, '00-49': 92.21, 'old': 92.21, 'new': nan}
2024-05-11 20:32:08,029 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 20:32:08,029 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21]
2024-05-11 20:32:08,029 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0]
2024-05-11 20:32:08,030 [trainer.py] => Average NME top1: 2.0
2024-05-11 20:32:08,030 [trainer.py] => Average top1: 88.24666666666666
2024-05-11 20:32:08,031 [trainer.py] => All params: 91441385
2024-05-11 20:32:08,031 [trainer.py] => Trainable params: 91441385
2024-05-11 20:32:08,032 [mbtc.py] => Learning on 150-200
2024-05-11 20:34:48,114 [mbtc.py] => Task 3, Epoch 1/10 => Loss 3.250
2024-05-11 20:34:48,114 [mbtc.py] => {'Train loss': 3.2500316995685385}
2024-05-11 20:36:00,837 [mbtc.py] => Task 3, Epoch 2/10 => Loss 0.947
2024-05-11 20:36:00,837 [mbtc.py] => {'Train loss': 0.9468062850883452}
2024-05-11 20:37:13,234 [mbtc.py] => Task 3, Epoch 3/10 => Loss 0.561
2024-05-11 20:37:13,235 [mbtc.py] => {'Train loss': 0.5612416671494306}
2024-05-11 20:38:26,083 [mbtc.py] => Task 3, Epoch 4/10 => Loss 0.470
2024-05-11 20:38:26,083 [mbtc.py] => {'Train loss': 0.4702373844082073}
2024-05-11 20:40:12,364 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:41:47,650 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:41:47,651 [mbtc.py] => {'Train acc': 91.53, 'Test acc': 91.69}
2024-05-11 20:41:47,651 [mbtc.py] => Task 3, Epoch 5/10 => Loss 0.417, Train_accy 91.530, Test_accy 91.690
2024-05-11 20:41:47,651 [mbtc.py] => {'Train loss': 0.41715564452490567}
2024-05-11 20:43:00,350 [mbtc.py] => Task 3, Epoch 6/10 => Loss 0.404
2024-05-11 20:43:00,351 [mbtc.py] => {'Train loss': 0.40363660921989863}
2024-05-11 20:44:12,858 [mbtc.py] => Task 3, Epoch 7/10 => Loss 0.345
2024-05-11 20:44:12,858 [mbtc.py] => {'Train loss': 0.34470689183069486}
2024-05-11 20:45:25,477 [mbtc.py] => Task 3, Epoch 8/10 => Loss 0.293
2024-05-11 20:45:25,477 [mbtc.py] => {'Train loss': 0.2933552445749105}
2024-05-11 20:46:38,031 [mbtc.py] => Task 3, Epoch 9/10 => Loss 0.291
2024-05-11 20:46:38,031 [mbtc.py] => {'Train loss': 0.2911987411394968}
2024-05-11 20:48:24,484 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:49:59,641 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:49:59,641 [mbtc.py] => {'Train acc': 93.22, 'Test acc': 93.07}
2024-05-11 20:49:59,641 [mbtc.py] => Task 3, Epoch 10/10 => Loss 0.270, Train_accy 93.220, Test_accy 93.070
2024-05-11 20:49:59,642 [mbtc.py] => {'Train loss': 0.26955078264414256}
2024-05-11 20:49:59,655 [mbtc.py] => Merge scalar: 0.25
2024-05-11 20:52:02,236 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 20:52:02,237 [mbtc.py] => Test accuracy of model after backbone merge: 93.71
2024-05-11 20:53:14,062 [mbtc.py] => Task 3, Epoch 1/5 => Loss 0.337
2024-05-11 20:53:14,062 [mbtc.py] => {'Train loss': 0.33676801735566836}
2024-05-11 20:54:25,915 [mbtc.py] => Task 3, Epoch 2/5 => Loss 0.303
2024-05-11 20:54:25,916 [mbtc.py] => {'Train loss': 0.3033104083043034}
2024-05-11 20:55:37,803 [mbtc.py] => Task 3, Epoch 3/5 => Loss 0.321
2024-05-11 20:55:37,804 [mbtc.py] => {'Train loss': 0.3214275574911449}
2024-05-11 20:56:49,592 [mbtc.py] => Task 3, Epoch 4/5 => Loss 0.297
2024-05-11 20:56:49,592 [mbtc.py] => {'Train loss': 0.2971109656964318}
2024-05-11 20:58:35,312 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:00:11,165 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:00:11,166 [mbtc.py] => {'Train acc': 91.96, 'Test acc': 93.68}
2024-05-11 21:00:11,166 [mbtc.py] => Task 3, Epoch 5/5 => Loss 0.298, Train_accy 91.960, Test_accy 93.680
2024-05-11 21:00:11,166 [mbtc.py] => {'Train loss': 0.2980151807857772}
2024-05-11 21:01:46,320 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:01:46,321 [mbtc.py] => Test accuracy of model after retraining: 93.68
2024-05-11 21:01:46,598 [mbtc.py] => The OT cost: 60.81621
2024-05-11 21:01:46,598 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:01:46,599 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:01:46,871 [mbtc.py] => The OT cost: 63.88626
2024-05-11 21:01:46,871 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:01:46,871 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:01:47,143 [mbtc.py] => The OT cost: 48.29008
2024-05-11 21:01:47,143 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:01:47,143 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:03:49,733 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:03:49,734 [mbtc.py] => Test accuracy of model after classifier transport: 93.7
2024-05-11 21:08:00,631 [trainer.py] => MBTC_VIT: {'total': 93.7, '00-49': 93.7, 'old': 93.7, 'new': nan}
2024-05-11 21:08:00,631 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 21:08:00,631 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21, 93.7]
2024-05-11 21:08:00,631 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0, 2.0]
2024-05-11 21:08:00,631 [trainer.py] => Average NME top1: 2.0
2024-05-11 21:08:00,631 [trainer.py] => Average top1: 89.60999999999999
2024-05-11 21:08:00,632 [trainer.py] => All params: 91479785
2024-05-11 21:08:00,633 [trainer.py] => Trainable params: 91479785
2024-05-11 21:08:00,633 [mbtc.py] => Learning on 200-250
2024-05-11 21:10:40,922 [mbtc.py] => Task 4, Epoch 1/10 => Loss 3.004
2024-05-11 21:10:40,923 [mbtc.py] => {'Train loss': 3.0043890688378934}
2024-05-11 21:11:53,390 [mbtc.py] => Task 4, Epoch 2/10 => Loss 0.693
2024-05-11 21:11:53,391 [mbtc.py] => {'Train loss': 0.6925848621433064}
2024-05-11 21:13:05,771 [mbtc.py] => Task 4, Epoch 3/10 => Loss 0.412
2024-05-11 21:13:05,772 [mbtc.py] => {'Train loss': 0.41198906277195885}
2024-05-11 21:14:18,060 [mbtc.py] => Task 4, Epoch 4/10 => Loss 0.331
2024-05-11 21:14:18,060 [mbtc.py] => {'Train loss': 0.33050376176834106}
2024-05-11 21:16:04,242 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:17:39,222 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:17:39,223 [mbtc.py] => {'Train acc': 94.12, 'Test acc': 92.57}
2024-05-11 21:17:39,223 [mbtc.py] => Task 4, Epoch 5/10 => Loss 0.281, Train_accy 94.120, Test_accy 92.570
2024-05-11 21:17:39,223 [mbtc.py] => {'Train loss': 0.28093877257937094}
2024-05-11 21:18:51,469 [mbtc.py] => Task 4, Epoch 6/10 => Loss 0.266
2024-05-11 21:18:51,469 [mbtc.py] => {'Train loss': 0.26566786514753005}
2024-05-11 21:20:03,842 [mbtc.py] => Task 4, Epoch 7/10 => Loss 0.237
2024-05-11 21:20:03,843 [mbtc.py] => {'Train loss': 0.23739580879524602}
2024-05-11 21:21:16,396 [mbtc.py] => Task 4, Epoch 8/10 => Loss 0.208
2024-05-11 21:21:16,397 [mbtc.py] => {'Train loss': 0.2080033396260213}
2024-05-11 21:22:28,783 [mbtc.py] => Task 4, Epoch 9/10 => Loss 0.201
2024-05-11 21:22:28,783 [mbtc.py] => {'Train loss': 0.20134819901974524}
2024-05-11 21:24:14,750 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:25:49,896 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:25:49,897 [mbtc.py] => {'Train acc': 95.38, 'Test acc': 93.51}
2024-05-11 21:25:49,897 [mbtc.py] => Task 4, Epoch 10/10 => Loss 0.183, Train_accy 95.380, Test_accy 93.510
2024-05-11 21:25:49,897 [mbtc.py] => {'Train loss': 0.18284780453196017}
2024-05-11 21:25:49,918 [mbtc.py] => Merge scalar: 0.25
2024-05-11 21:27:52,454 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:27:52,455 [mbtc.py] => Test accuracy of model after backbone merge: 94.32
2024-05-11 21:29:04,203 [mbtc.py] => Task 4, Epoch 1/5 => Loss 0.204
2024-05-11 21:29:04,203 [mbtc.py] => {'Train loss': 0.2038027410853212}
2024-05-11 21:30:15,910 [mbtc.py] => Task 4, Epoch 2/5 => Loss 0.189
2024-05-11 21:30:15,910 [mbtc.py] => {'Train loss': 0.18927014514930168}
2024-05-11 21:31:27,870 [mbtc.py] => Task 4, Epoch 3/5 => Loss 0.184
2024-05-11 21:31:27,870 [mbtc.py] => {'Train loss': 0.18376845754367316}
2024-05-11 21:32:39,683 [mbtc.py] => Task 4, Epoch 4/5 => Loss 0.187
2024-05-11 21:32:39,683 [mbtc.py] => {'Train loss': 0.18746136463547158}
2024-05-11 21:34:25,049 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:36:00,245 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:36:00,245 [mbtc.py] => {'Train acc': 94.7, 'Test acc': 94.31}
2024-05-11 21:36:00,245 [mbtc.py] => Task 4, Epoch 5/5 => Loss 0.187, Train_accy 94.700, Test_accy 94.310
2024-05-11 21:36:00,245 [mbtc.py] => {'Train loss': 0.18694786020254683}
2024-05-11 21:37:35,920 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:37:35,921 [mbtc.py] => Test accuracy of model after retraining: 94.31
2024-05-11 21:37:36,204 [mbtc.py] => The OT cost: 58.04232
2024-05-11 21:37:36,204 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:37:36,205 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:37:36,476 [mbtc.py] => The OT cost: 60.25097
2024-05-11 21:37:36,476 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:37:36,476 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:37:36,748 [mbtc.py] => The OT cost: 44.23648
2024-05-11 21:37:36,748 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:37:36,749 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:37:37,020 [mbtc.py] => The OT cost: 45.82011
2024-05-11 21:37:37,020 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 21:37:37,020 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 21:39:40,143 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:39:40,144 [mbtc.py] => Test accuracy of model after classifier transport: 94.35
2024-05-11 21:43:52,279 [trainer.py] => MBTC_VIT: {'total': 94.35, '00-49': 94.35, 'old': 94.35, 'new': nan}
2024-05-11 21:43:52,279 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 21:43:52,279 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21, 93.7, 94.35]
2024-05-11 21:43:52,279 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0, 2.0, 2.0]
2024-05-11 21:43:52,279 [trainer.py] => Average NME top1: 2.0
2024-05-11 21:43:52,280 [trainer.py] => Average top1: 90.55799999999999
2024-05-11 21:43:52,280 [trainer.py] => All params: 91518185
2024-05-11 21:43:52,281 [trainer.py] => Trainable params: 91518185
2024-05-11 21:43:52,281 [mbtc.py] => Learning on 250-300
2024-05-11 21:46:31,495 [mbtc.py] => Task 5, Epoch 1/10 => Loss 3.177
2024-05-11 21:46:31,496 [mbtc.py] => {'Train loss': 3.177182824934943}
2024-05-11 21:47:43,913 [mbtc.py] => Task 5, Epoch 2/10 => Loss 0.805
2024-05-11 21:47:43,914 [mbtc.py] => {'Train loss': 0.805153143860526}
2024-05-11 21:48:56,571 [mbtc.py] => Task 5, Epoch 3/10 => Loss 0.456
2024-05-11 21:48:56,571 [mbtc.py] => {'Train loss': 0.4557832182716515}
2024-05-11 21:50:09,172 [mbtc.py] => Task 5, Epoch 4/10 => Loss 0.361
2024-05-11 21:50:09,173 [mbtc.py] => {'Train loss': 0.36069169880475027}
2024-05-11 21:51:55,400 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:53:30,550 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 21:53:30,551 [mbtc.py] => {'Train acc': 93.44, 'Test acc': 92.72}
2024-05-11 21:53:30,551 [mbtc.py] => Task 5, Epoch 5/10 => Loss 0.309, Train_accy 93.440, Test_accy 92.720
2024-05-11 21:53:30,551 [mbtc.py] => {'Train loss': 0.308771102736562}
2024-05-11 21:54:42,916 [mbtc.py] => Task 5, Epoch 6/10 => Loss 0.294
2024-05-11 21:54:42,916 [mbtc.py] => {'Train loss': 0.2944236117399345}
2024-05-11 21:55:55,582 [mbtc.py] => Task 5, Epoch 7/10 => Loss 0.237
2024-05-11 21:55:55,583 [mbtc.py] => {'Train loss': 0.23683493900097022}
2024-05-11 21:57:08,115 [mbtc.py] => Task 5, Epoch 8/10 => Loss 0.221
2024-05-11 21:57:08,115 [mbtc.py] => {'Train loss': 0.220931175243804}
2024-05-11 21:58:20,762 [mbtc.py] => Task 5, Epoch 9/10 => Loss 0.197
2024-05-11 21:58:20,763 [mbtc.py] => {'Train loss': 0.19727052868170253}
2024-05-11 22:00:06,954 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:01:41,900 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:01:41,901 [mbtc.py] => {'Train acc': 95.28, 'Test acc': 93.17}
2024-05-11 22:01:41,901 [mbtc.py] => Task 5, Epoch 10/10 => Loss 0.192, Train_accy 95.280, Test_accy 93.170
2024-05-11 22:01:41,901 [mbtc.py] => {'Train loss': 0.19158856861167034}
2024-05-11 22:01:41,917 [mbtc.py] => Merge scalar: 0.25
2024-05-11 22:03:44,434 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:03:44,435 [mbtc.py] => Test accuracy of model after backbone merge: 94.57
2024-05-11 22:04:56,193 [mbtc.py] => Task 5, Epoch 1/5 => Loss 0.279
2024-05-11 22:04:56,193 [mbtc.py] => {'Train loss': 0.2788818784184375}
2024-05-11 22:06:08,170 [mbtc.py] => Task 5, Epoch 2/5 => Loss 0.244
2024-05-11 22:06:08,171 [mbtc.py] => {'Train loss': 0.24368351129657131}
2024-05-11 22:07:19,970 [mbtc.py] => Task 5, Epoch 3/5 => Loss 0.229
2024-05-11 22:07:19,971 [mbtc.py] => {'Train loss': 0.22945491110874436}
2024-05-11 22:08:31,775 [mbtc.py] => Task 5, Epoch 4/5 => Loss 0.217
2024-05-11 22:08:31,775 [mbtc.py] => {'Train loss': 0.2171597285669739}
2024-05-11 22:10:17,139 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:11:51,951 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:11:51,952 [mbtc.py] => {'Train acc': 94.61, 'Test acc': 94.6}
2024-05-11 22:11:51,952 [mbtc.py] => Task 5, Epoch 5/5 => Loss 0.219, Train_accy 94.610, Test_accy 94.600
2024-05-11 22:11:51,952 [mbtc.py] => {'Train loss': 0.21855555752576408}
2024-05-11 22:13:26,809 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:13:26,810 [mbtc.py] => Test accuracy of model after retraining: 94.6
2024-05-11 22:13:27,099 [mbtc.py] => The OT cost: 65.94589
2024-05-11 22:13:27,099 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:13:27,099 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:13:27,371 [mbtc.py] => The OT cost: 64.36978
2024-05-11 22:13:27,371 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:13:27,371 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:13:27,648 [mbtc.py] => The OT cost: 67.77724
2024-05-11 22:13:27,648 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:13:27,649 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:13:27,921 [mbtc.py] => The OT cost: 65.72729
2024-05-11 22:13:27,921 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:13:27,922 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:13:28,196 [mbtc.py] => The OT cost: 67.13044
2024-05-11 22:13:28,197 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:13:28,197 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:15:30,820 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:15:30,820 [mbtc.py] => Test accuracy of model after classifier transport: 94.63
2024-05-11 22:19:43,566 [trainer.py] => MBTC_VIT: {'total': 94.63, '00-49': 94.63, 'old': 94.63, 'new': nan}
2024-05-11 22:19:43,566 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 22:19:43,566 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21, 93.7, 94.35, 94.63]
2024-05-11 22:19:43,566 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
2024-05-11 22:19:43,566 [trainer.py] => Average NME top1: 2.0
2024-05-11 22:19:43,566 [trainer.py] => Average top1: 91.23666666666666
2024-05-11 22:19:43,567 [trainer.py] => All params: 91556585
2024-05-11 22:19:43,568 [trainer.py] => Trainable params: 91556585
2024-05-11 22:19:43,568 [mbtc.py] => Learning on 300-350
2024-05-11 22:22:22,659 [mbtc.py] => Task 6, Epoch 1/10 => Loss 3.068
2024-05-11 22:22:22,659 [mbtc.py] => {'Train loss': 3.06779085774707}
2024-05-11 22:23:34,572 [mbtc.py] => Task 6, Epoch 2/10 => Loss 0.729
2024-05-11 22:23:34,572 [mbtc.py] => {'Train loss': 0.7289927706249759}
2024-05-11 22:24:46,676 [mbtc.py] => Task 6, Epoch 3/10 => Loss 0.441
2024-05-11 22:24:46,677 [mbtc.py] => {'Train loss': 0.4409448605062615}
2024-05-11 22:25:58,869 [mbtc.py] => Task 6, Epoch 4/10 => Loss 0.342
2024-05-11 22:25:58,869 [mbtc.py] => {'Train loss': 0.34152921410197884}
2024-05-11 22:27:44,485 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:29:19,785 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:29:19,785 [mbtc.py] => {'Train acc': 94.02, 'Test acc': 92.72}
2024-05-11 22:29:19,785 [mbtc.py] => Task 6, Epoch 5/10 => Loss 0.294, Train_accy 94.020, Test_accy 92.720
2024-05-11 22:29:19,786 [mbtc.py] => {'Train loss': 0.2938503516662834}
2024-05-11 22:30:31,924 [mbtc.py] => Task 6, Epoch 6/10 => Loss 0.282
2024-05-11 22:30:31,925 [mbtc.py] => {'Train loss': 0.2817728284459848}
2024-05-11 22:31:44,231 [mbtc.py] => Task 6, Epoch 7/10 => Loss 0.226
2024-05-11 22:31:44,232 [mbtc.py] => {'Train loss': 0.22633088310050148}
2024-05-11 22:32:56,515 [mbtc.py] => Task 6, Epoch 8/10 => Loss 0.209
2024-05-11 22:32:56,516 [mbtc.py] => {'Train loss': 0.2093978314063488}
2024-05-11 22:34:08,748 [mbtc.py] => Task 6, Epoch 9/10 => Loss 0.206
2024-05-11 22:34:08,749 [mbtc.py] => {'Train loss': 0.20580840556540042}
2024-05-11 22:35:54,858 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:37:29,955 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:37:29,956 [mbtc.py] => {'Train acc': 95.32, 'Test acc': 93.15}
2024-05-11 22:37:29,956 [mbtc.py] => Task 6, Epoch 10/10 => Loss 0.187, Train_accy 95.320, Test_accy 93.150
2024-05-11 22:37:29,956 [mbtc.py] => {'Train loss': 0.18672977012192082}
2024-05-11 22:37:29,970 [mbtc.py] => Merge scalar: 0.25
2024-05-11 22:39:32,998 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:39:32,999 [mbtc.py] => Test accuracy of model after backbone merge: 94.04
2024-05-11 22:40:44,778 [mbtc.py] => Task 6, Epoch 1/5 => Loss 0.249
2024-05-11 22:40:44,779 [mbtc.py] => {'Train loss': 0.2494292210819375}
2024-05-11 22:41:56,314 [mbtc.py] => Task 6, Epoch 2/5 => Loss 0.217
2024-05-11 22:41:56,315 [mbtc.py] => {'Train loss': 0.21743951158391106}
2024-05-11 22:43:07,858 [mbtc.py] => Task 6, Epoch 3/5 => Loss 0.205
2024-05-11 22:43:07,858 [mbtc.py] => {'Train loss': 0.2052960609141578}
2024-05-11 22:44:19,214 [mbtc.py] => Task 6, Epoch 4/5 => Loss 0.213
2024-05-11 22:44:19,214 [mbtc.py] => {'Train loss': 0.21340205042790145}
2024-05-11 22:46:04,684 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:47:39,637 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:47:39,638 [mbtc.py] => {'Train acc': 94.99, 'Test acc': 94.19}
2024-05-11 22:47:39,638 [mbtc.py] => Task 6, Epoch 5/5 => Loss 0.200, Train_accy 94.990, Test_accy 94.190
2024-05-11 22:47:39,638 [mbtc.py] => {'Train loss': 0.20010536367821896}
2024-05-11 22:49:14,378 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:49:14,379 [mbtc.py] => Test accuracy of model after retraining: 94.19
2024-05-11 22:49:14,678 [mbtc.py] => The OT cost: 60.15762
2024-05-11 22:49:14,678 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:14,678 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:49:14,951 [mbtc.py] => The OT cost: 62.84749
2024-05-11 22:49:14,951 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:14,951 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:49:15,224 [mbtc.py] => The OT cost: 58.00409
2024-05-11 22:49:15,224 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:15,225 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:49:15,525 [mbtc.py] => The OT cost: 55.34111
2024-05-11 22:49:15,525 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:15,525 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:49:15,796 [mbtc.py] => The OT cost: 55.07345
2024-05-11 22:49:15,796 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:15,797 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:49:16,073 [mbtc.py] => The OT cost: 59.21092
2024-05-11 22:49:16,073 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 22:49:16,073 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 22:51:18,615 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 22:51:18,616 [mbtc.py] => Test accuracy of model after classifier transport: 94.2
2024-05-11 22:55:35,669 [trainer.py] => MBTC_VIT: {'total': 94.2, '00-49': 94.2, 'old': 94.2, 'new': nan}
2024-05-11 22:55:35,669 [trainer.py] => NME: {'total': 2.09, '00-49': 2.09, 'old': 2.09, 'new': nan}
2024-05-11 22:55:35,669 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21, 93.7, 94.35, 94.63, 94.2]
2024-05-11 22:55:35,670 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.09]
2024-05-11 22:55:35,670 [trainer.py] => Average NME top1: 2.012857142857143
2024-05-11 22:55:35,670 [trainer.py] => Average top1: 91.66
2024-05-11 22:55:35,671 [trainer.py] => All params: 91594985
2024-05-11 22:55:35,671 [trainer.py] => Trainable params: 91594985
2024-05-11 22:55:35,671 [mbtc.py] => Learning on 350-400
2024-05-11 22:58:16,930 [mbtc.py] => Task 7, Epoch 1/10 => Loss 3.108
2024-05-11 22:58:16,930 [mbtc.py] => {'Train loss': 3.10823111059302}
2024-05-11 22:59:29,475 [mbtc.py] => Task 7, Epoch 2/10 => Loss 0.758
2024-05-11 22:59:29,475 [mbtc.py] => {'Train loss': 0.7580331894805876}
2024-05-11 23:00:41,919 [mbtc.py] => Task 7, Epoch 3/10 => Loss 0.430
2024-05-11 23:00:41,919 [mbtc.py] => {'Train loss': 0.4303810169636193}
2024-05-11 23:01:54,453 [mbtc.py] => Task 7, Epoch 4/10 => Loss 0.356
2024-05-11 23:01:54,454 [mbtc.py] => {'Train loss': 0.3555542954196364}
2024-05-11 23:03:40,701 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:05:15,716 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:05:15,717 [mbtc.py] => {'Train acc': 93.53, 'Test acc': 94.01}
2024-05-11 23:05:15,717 [mbtc.py] => Task 7, Epoch 5/10 => Loss 0.310, Train_accy 93.530, Test_accy 94.010
2024-05-11 23:05:15,717 [mbtc.py] => {'Train loss': 0.3103227416148125}
2024-05-11 23:06:27,960 [mbtc.py] => Task 7, Epoch 6/10 => Loss 0.272
2024-05-11 23:06:27,961 [mbtc.py] => {'Train loss': 0.2717744392358651}
2024-05-11 23:07:40,559 [mbtc.py] => Task 7, Epoch 7/10 => Loss 0.248
2024-05-11 23:07:40,559 [mbtc.py] => {'Train loss': 0.24805917060476237}
2024-05-11 23:08:53,370 [mbtc.py] => Task 7, Epoch 8/10 => Loss 0.220
2024-05-11 23:08:53,371 [mbtc.py] => {'Train loss': 0.2196495763768079}
2024-05-11 23:10:05,886 [mbtc.py] => Task 7, Epoch 9/10 => Loss 0.203
2024-05-11 23:10:05,887 [mbtc.py] => {'Train loss': 0.2033736232226178}
2024-05-11 23:11:52,242 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:13:27,347 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:13:27,348 [mbtc.py] => {'Train acc': 95.19, 'Test acc': 94.35}
2024-05-11 23:13:27,348 [mbtc.py] => Task 7, Epoch 10/10 => Loss 0.196, Train_accy 95.190, Test_accy 94.350
2024-05-11 23:13:27,348 [mbtc.py] => {'Train loss': 0.19597485399473522}
2024-05-11 23:13:27,365 [mbtc.py] => Merge scalar: 0.25
2024-05-11 23:15:29,869 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:15:29,870 [mbtc.py] => Test accuracy of model after backbone merge: 93.76
2024-05-11 23:16:41,766 [mbtc.py] => Task 7, Epoch 1/5 => Loss 0.267
2024-05-11 23:16:41,767 [mbtc.py] => {'Train loss': 0.26683441723175977}
2024-05-11 23:17:53,480 [mbtc.py] => Task 7, Epoch 2/5 => Loss 0.240
2024-05-11 23:17:53,481 [mbtc.py] => {'Train loss': 0.23983421505002653}
2024-05-11 23:19:05,145 [mbtc.py] => Task 7, Epoch 3/5 => Loss 0.232
2024-05-11 23:19:05,145 [mbtc.py] => {'Train loss': 0.23168408775986252}
2024-05-11 23:20:17,003 [mbtc.py] => Task 7, Epoch 4/5 => Loss 0.218
2024-05-11 23:20:17,004 [mbtc.py] => {'Train loss': 0.21754242031503532}
2024-05-11 23:22:02,527 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:23:38,384 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:23:38,385 [mbtc.py] => {'Train acc': 94.43, 'Test acc': 94.52}
2024-05-11 23:23:38,385 [mbtc.py] => Task 7, Epoch 5/5 => Loss 0.199, Train_accy 94.430, Test_accy 94.520
2024-05-11 23:23:38,385 [mbtc.py] => {'Train loss': 0.1991453709049245}
2024-05-11 23:25:13,506 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:25:13,507 [mbtc.py] => Test accuracy of model after retraining: 94.52
2024-05-11 23:25:13,787 [mbtc.py] => The OT cost: 61.26796
2024-05-11 23:25:13,787 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:13,787 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:14,057 [mbtc.py] => The OT cost: 63.75270
2024-05-11 23:25:14,058 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:14,058 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:14,327 [mbtc.py] => The OT cost: 40.77295
2024-05-11 23:25:14,327 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:14,328 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:14,597 [mbtc.py] => The OT cost: 48.44634
2024-05-11 23:25:14,598 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:14,598 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:14,875 [mbtc.py] => The OT cost: 45.12491
2024-05-11 23:25:14,875 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:14,875 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:15,146 [mbtc.py] => The OT cost: 67.90987
2024-05-11 23:25:15,146 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:15,146 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:25:15,421 [mbtc.py] => The OT cost: 60.04235
2024-05-11 23:25:15,421 [mbtc.py] => Head merge ratio: 0.25
2024-05-11 23:25:15,421 [mbtc.py] => Distance between old head weight and updated head weight: 0.0000000000
2024-05-11 23:27:17,984 [base.py] => Hint: You are using _compute_accuracy_domain().
2024-05-11 23:27:17,985 [mbtc.py] => Test accuracy of model after classifier transport: 94.83
2024-05-11 23:31:33,856 [trainer.py] => MBTC_VIT: {'total': 94.83, '00-49': 94.83, 'old': 94.83, 'new': nan}
2024-05-11 23:31:33,857 [trainer.py] => NME: {'total': 2.0, '00-49': 2.0, 'old': 2.0, 'new': nan}
2024-05-11 23:31:33,857 [trainer.py] => MBTC_VIT top1 curve: [82.96, 89.57, 92.21, 93.7, 94.35, 94.63, 94.2, 94.83]
2024-05-11 23:31:33,857 [trainer.py] => NME top1 curve: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.09, 2.0]
2024-05-11 23:31:33,857 [trainer.py] => Average NME top1: 2.01125
2024-05-11 23:31:33,857 [trainer.py] => Average top1: 92.05624999999999
2024-05-11 23:31:33,857 [trainer.py] => Accuracy Matrix:
2024-05-11 23:31:33,857 [trainer.py] => [82.96  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,858 [trainer.py] => [89.57  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,858 [trainer.py] => [92.21  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,859 [trainer.py] => [93.7  0.   0.   0.   0.   0.   0.   0. ]
2024-05-11 23:31:33,859 [trainer.py] => [94.35  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,859 [trainer.py] => [94.63  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,859 [trainer.py] => [94.2  0.   0.   0.   0.   0.   0.   0. ]
2024-05-11 23:31:33,860 [trainer.py] => [94.83  0.    0.    0.    0.    0.    0.    0.  ]
2024-05-11 23:31:33,860 [trainer.py] => Forgetting (after last task): 0.0
2024-05-11 23:31:33,860 [trainer.py] => NME Accuracy Matrix:
2024-05-11 23:31:33,860 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,861 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,861 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,861 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,861 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,862 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,862 [trainer.py] => [2.09 0.   0.   0.   0.   0.   0.   0.  ]
2024-05-11 23:31:33,862 [trainer.py] => [2. 0. 0. 0. 0. 0. 0. 0.]
2024-05-11 23:31:33,863 [trainer.py] => NME Forgetting (after last task): 0.012857142857142836
